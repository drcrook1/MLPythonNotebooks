{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to predict actual wages based on a minimalist survey\n",
    "\n",
    "We will start by simply inspecting some basic information regarding the data, select a few columns to use as predictors for 'fnlwgt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Explore\n",
    "\n",
    "Below we simply read the data, print out the columns, view the first 5 rows and check out some basic numerical statistics.  We also view the full scope of responses we have.\n",
    "\n",
    "For now we are going to simply ignore the distribution of data in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' ' workclass' ' fnlwgt' ' education' ' education-num'\n",
      " ' marital-status' ' occupation' ' relationship' ' race' ' sex'\n",
      " ' capital-gain' ' capital-loss' ' hours-per-week' ' native-country'\n",
      " ' income']\n",
      "###########\n",
      "   age          workclass   fnlwgt   education   education-num  \\\n",
      "0   39          State-gov    77516   Bachelors              13   \n",
      "1   50   Self-emp-not-inc    83311   Bachelors              13   \n",
      "2   38            Private   215646     HS-grad               9   \n",
      "3   53            Private   234721        11th               7   \n",
      "4   28            Private   338409   Bachelors              13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "    capital-gain   capital-loss   hours-per-week  native-country  income  \n",
      "0           2174              0               40   United-States   <=50K  \n",
      "1              0              0               13   United-States   <=50K  \n",
      "2              0              0               40   United-States   <=50K  \n",
      "3              0              0               40   United-States   <=50K  \n",
      "4              0              0               40            Cuba   <=50K  \n",
      "###########\n",
      "                age        fnlwgt   education-num   capital-gain  \\\n",
      "count  32561.000000  3.256100e+04    32561.000000   32561.000000   \n",
      "mean      38.581647  1.897784e+05       10.080679    1077.648844   \n",
      "std       13.640433  1.055500e+05        2.572720    7385.292085   \n",
      "min       17.000000  1.228500e+04        1.000000       0.000000   \n",
      "25%       28.000000  1.178270e+05        9.000000       0.000000   \n",
      "50%       37.000000  1.783560e+05       10.000000       0.000000   \n",
      "75%       48.000000  2.370510e+05       12.000000       0.000000   \n",
      "max       90.000000  1.484705e+06       16.000000   99999.000000   \n",
      "\n",
      "        capital-loss   hours-per-week  \n",
      "count   32561.000000     32561.000000  \n",
      "mean       87.303830        40.437456  \n",
      "std       402.960219        12.347429  \n",
      "min         0.000000         1.000000  \n",
      "25%         0.000000        40.000000  \n",
      "50%         0.000000        40.000000  \n",
      "75%         0.000000        45.000000  \n",
      "max      4356.000000        99.000000  \n"
     ]
    }
   ],
   "source": [
    "DATA_FILE_PATH = 'C:/data/AdultCensusIncome.csv'\n",
    "data = pd.read_csv(DATA_FILE_PATH)\n",
    "print(data.columns.values)\n",
    "print('###########')\n",
    "print(data[0:5])\n",
    "print('###########')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' ' fnlwgt' ' education-num' ' capital-gain' ' capital-loss'\n",
      " ' hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = data.describe().columns.values\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' workclass' ' education' ' marital-status' ' occupation' ' relationship'\n",
      " ' race' ' sex' ' native-country' ' income']\n"
     ]
    }
   ],
   "source": [
    "categorical_df = data.drop(numeric_cols, axis=1)\n",
    "print(categorical_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- COLUMN:  workclass ----------\n",
      "{' Private', ' Without-pay', ' Self-emp-not-inc', ' Never-worked', ' State-gov', ' Self-emp-inc', ' ?', ' Local-gov', ' Federal-gov'}\n",
      "num_unique: 9\n",
      "------- COLUMN:  education ----------\n",
      "{' 7th-8th', ' Assoc-acdm', ' Bachelors', ' Prof-school', ' Masters', ' 9th', ' Doctorate', ' 10th', ' 1st-4th', ' 12th', ' Preschool', ' Assoc-voc', ' 11th', ' 5th-6th', ' HS-grad', ' Some-college'}\n",
      "num_unique: 16\n",
      "------- COLUMN:  marital-status ----------\n",
      "{' Separated', ' Widowed', ' Married-AF-spouse', ' Married-spouse-absent', ' Never-married', ' Married-civ-spouse', ' Divorced'}\n",
      "num_unique: 7\n",
      "------- COLUMN:  occupation ----------\n",
      "{' Machine-op-inspct', ' Tech-support', ' Adm-clerical', ' Sales', ' Protective-serv', ' Handlers-cleaners', ' Other-service', ' Craft-repair', ' ?', ' Armed-Forces', ' Transport-moving', ' Prof-specialty', ' Exec-managerial', ' Farming-fishing', ' Priv-house-serv'}\n",
      "num_unique: 15\n",
      "------- COLUMN:  relationship ----------\n",
      "{' Not-in-family', ' Husband', ' Own-child', ' Other-relative', ' Unmarried', ' Wife'}\n",
      "num_unique: 6\n",
      "------- COLUMN:  race ----------\n",
      "{' Asian-Pac-Islander', ' Black', ' White', ' Other', ' Amer-Indian-Eskimo'}\n",
      "num_unique: 5\n",
      "------- COLUMN:  sex ----------\n",
      "{' Female', ' Male'}\n",
      "num_unique: 2\n",
      "------- COLUMN:  native-country ----------\n",
      "{' Ireland', ' France', ' Greece', ' Mexico', ' England', ' Yugoslavia', ' Ecuador', ' Canada', ' Holand-Netherlands', ' Dominican-Republic', ' Outlying-US(Guam-USVI-etc)', ' Thailand', ' Japan', ' Puerto-Rico', ' Trinadad&Tobago', ' Cuba', ' Iran', ' Taiwan', ' Guatemala', ' Peru', ' Italy', ' Laos', ' Poland', ' Columbia', ' Hungary', ' Jamaica', ' Scotland', ' Portugal', ' Cambodia', ' Haiti', ' Nicaragua', ' ?', ' United-States', ' Honduras', ' India', ' China', ' South', ' Hong', ' Germany', ' Vietnam', ' Philippines', ' El-Salvador'}\n",
      "num_unique: 42\n",
      "------- COLUMN:  income ----------\n",
      "{' <=50K', ' >50K'}\n",
      "num_unique: 2\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_df.columns.values:\n",
    "    print('------- COLUMN: ' + col + ' ----------')\n",
    "    unique_vals = set(data[col])\n",
    "    print(unique_vals)\n",
    "    print('num_unique: ' + str(len(unique_vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets build a survey and think of questions we want to ask.\n",
    "\n",
    "Age, Sex, Race, Education, workclass, relation, hours per week.  \n",
    "\n",
    "First step is to build a data frame with just that data AND the column we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex   race  education         workclass   relationship  \\\n",
      "0   39    Male  White  Bachelors         State-gov  Not-in-family   \n",
      "1   50    Male  White  Bachelors  Self-emp-not-inc        Husband   \n",
      "2   38    Male  White    HS-grad           Private  Not-in-family   \n",
      "3   53    Male  Black       11th           Private        Husband   \n",
      "4   28  Female  Black  Bachelors           Private           Wife   \n",
      "\n",
      "    hours-per-week   fnlwgt  \n",
      "0               40    77516  \n",
      "1               13    83311  \n",
      "2               40   215646  \n",
      "3               40   234721  \n",
      "4               40   338409  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Start by getting just the data we want.\n",
    "#\n",
    "\n",
    "#Some data isn't very clean, so add extra spaces to the front of the column names.\n",
    "prediction_df = data[['age', ' sex', ' race', ' education', ' workclass', ' relationship', ' hours-per-week', ' fnlwgt']]\n",
    "\n",
    "#\n",
    "# Lets go ahead an also clean up the values in each column.\n",
    "#\n",
    "for col in prediction_df.columns.values:\n",
    "    if(prediction_df[col].dtype == 'object'):\n",
    "        prediction_df[col] = prediction_df[col].apply(lambda x: x.strip())\n",
    "\n",
    "print(prediction_df[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# We one hot encode ONLY categorical data.  \n",
    "#\n",
    "# We need to One-Hot Encode data.  To do this, first we need to build a class mapping\n",
    "# We will extract information from this, and then transform into the proper representation\n",
    "#\n",
    "\n",
    "#get mappings\n",
    "age_map = list(set(prediction_df['age']))\n",
    "sex_map = list(set(prediction_df[' sex']))\n",
    "race_map = list(set(prediction_df[' race']))\n",
    "ed_map = list(set(prediction_df[' education']))\n",
    "work_map = list(set(prediction_df[' workclass']))\n",
    "rel_map = list(set(prediction_df[' relationship']))\n",
    "\n",
    "def One_Hot(value, mapping):\n",
    "    '''Takes a value and a mapping.  Returns the one hot encoded representation of the value.'''\n",
    "    return np.eye(len(mapping))[mapping.index(value)]\n",
    "\n",
    "# Apply the encodings to each column\n",
    "prediction_df['age'] = prediction_df['age'].apply(lambda x: One_Hot(x, age_map))\n",
    "prediction_df[' sex'] = prediction_df[' sex'].apply(lambda x: One_Hot(x, sex_map))\n",
    "prediction_df[' race'] = prediction_df[' race'].apply(lambda x: One_Hot(x, race_map))\n",
    "prediction_df[' education'] = prediction_df[' education'].apply(lambda x: One_Hot(x, ed_map))\n",
    "prediction_df[' workclass'] = prediction_df[' workclass'].apply(lambda x: One_Hot(x, work_map))\n",
    "prediction_df[' relationship'] = prediction_df[' relationship'].apply(lambda x: One_Hot(x, rel_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     age         sex  \\\n",
      "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "5      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "6      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "7      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "8      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "9      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "10     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "11     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "12     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "13     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "14     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "15     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "16     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  [1.0, 0.0]   \n",
      "17     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "18     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "19     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "20     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "21     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "22     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "23     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "24     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "25     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "26     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "27     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "28     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "29     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "...                                                  ...         ...   \n",
      "32531  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32532  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32533  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32534  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32535  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32536  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32537  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32538  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32539  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32540  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32541  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32542  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32543  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32544  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32545  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32546  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32547  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32548  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32549  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32550  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32551  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32552  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32553  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32554  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32555  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32556  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32557  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32558  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "32559  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  [1.0, 0.0]   \n",
      "32560  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 1.0]   \n",
      "\n",
      "                            race  \\\n",
      "0      [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "3      [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "4      [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "5      [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "6      [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "7      [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "8      [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "9      [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "10     [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "11     [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "12     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "13     [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "14     [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "15     [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "16     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "17     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "18     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "19     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "20     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "21     [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "22     [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "23     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "24     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "25     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "26     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "27     [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "28     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "29     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "...                          ...   \n",
      "32531  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "32532  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32533  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "32534  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32535  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32536  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32537  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32538  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32539  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32540  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32541  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32542  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32543  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32544  [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
      "32545  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32546  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32547  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32548  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32549  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32550  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32551  [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "32552  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32553  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "32554  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32555  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32556  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32557  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32558  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32559  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "32560  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
      "\n",
      "                                               education  \\\n",
      "0      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
      "4      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "5      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "6      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "7      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "8      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "9      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "10     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "11     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "12     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "13     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "14     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
      "15     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "16     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "17     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "18     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
      "19     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "20     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "21     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "22     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "23     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
      "24     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "25     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "26     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "27     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "28     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "29     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "...                                                  ...   \n",
      "32531  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32532  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32533  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32534  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32535  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32536  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32537  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32538  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32539  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32540  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32541  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32542  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32543  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32544  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32545  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32546  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32547  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32548  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
      "32549  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32550  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32551  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32552  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
      "32553  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32554  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32555  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32556  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32557  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32558  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32559  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "32560  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                           workclass  \\\n",
      "0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "5      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "6      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "7      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
      "8      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "9      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "10     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "11     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "12     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "13     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "14     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "15     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "16     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
      "17     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "18     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "19     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
      "20     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "21     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "22     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "23     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "24     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "25     [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "26     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "27     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "28     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "29     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "...                                              ...   \n",
      "32531  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "32532  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32533  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32534  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32535  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32536  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32537  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32538  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32539  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "32540  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "32541  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "32542  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "32543  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "32544  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32545  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "32546  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32547  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32548  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
      "32549  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "32550  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
      "32551  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32552  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32553  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32554  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32555  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32556  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32557  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32558  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32559  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "32560  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "\n",
      "                         relationship   hours-per-week   fnlwgt  \n",
      "0      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               40    77516  \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               13    83311  \n",
      "2      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               40   215646  \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   234721  \n",
      "4      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]               40   338409  \n",
      "5      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]               40   284582  \n",
      "6      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               16   160187  \n",
      "7      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               45   209642  \n",
      "8      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               50    45781  \n",
      "9      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   159449  \n",
      "10     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               80   280464  \n",
      "11     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   141297  \n",
      "12     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]               30   122272  \n",
      "13     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               50   205019  \n",
      "14     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   121772  \n",
      "15     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               45   245487  \n",
      "16     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]               35   176756  \n",
      "17     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               40   186824  \n",
      "18     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               50    28887  \n",
      "19     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               45   292175  \n",
      "20     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               60   193524  \n",
      "21     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               20   302146  \n",
      "22     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40    76845  \n",
      "23     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   117037  \n",
      "24     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               40   109015  \n",
      "25     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   216851  \n",
      "26     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]               40   168294  \n",
      "27     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               60   180211  \n",
      "28     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               80   367260  \n",
      "29     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   193366  \n",
      "...                               ...              ...      ...  \n",
      "32531  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               99    33811  \n",
      "32532  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               60   204461  \n",
      "32533  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               50   337992  \n",
      "32534  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               39   179137  \n",
      "32535  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]               35   325033  \n",
      "32536  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               55   160216  \n",
      "32537  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               46   345898  \n",
      "32538  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               45   139180  \n",
      "32539  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               10   287372  \n",
      "32540  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]               40   252208  \n",
      "32541  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               32   202822  \n",
      "32542  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               25   129912  \n",
      "32543  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               48   119199  \n",
      "32544  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               30   199655  \n",
      "32545  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]               20   111499  \n",
      "32546  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               40   198216  \n",
      "32547  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   260761  \n",
      "32548  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               60    99359  \n",
      "32549  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]               40   255835  \n",
      "32550  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               50    27242  \n",
      "32551  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40    34066  \n",
      "32552  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               45    84661  \n",
      "32553  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               11   116138  \n",
      "32554  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   321865  \n",
      "32555  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]               40   310152  \n",
      "32556  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]               38   257302  \n",
      "32557  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]               40   154374  \n",
      "32558  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]               40   151910  \n",
      "32559  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]               20   201490  \n",
      "32560  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]               40   287927  \n",
      "\n",
      "[32561 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Machine Learning\n",
    "\n",
    "Seperate our features from our prediction, Convert to Numpy Matrices and then split data\n",
    "\n",
    "Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------FULL FRAME------\n",
      "age                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      " sex                                                      [1.0, 0.0]\n",
      " race                                      [0.0, 0.0, 0.0, 0.0, 1.0]\n",
      " education         [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      " workclass             [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      " relationship                         [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      " hours-per-week                                                   40\n",
      " fnlwgt                                                        77516\n",
      "Name: 0, dtype: object\n",
      "-----JUST Y---------\n",
      "77516\n",
      "-----JUST X--------\n",
      "age                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      " sex                                                      [1.0, 0.0]\n",
      " race                                      [0.0, 0.0, 0.0, 0.0, 1.0]\n",
      " education         [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      " workclass             [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      " relationship                         [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      " hours-per-week                                                   40\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we seperate into 'features' or predictors - X\n",
    "# and 'labels' or truths - Y\n",
    "#\n",
    "Y = prediction_df[' fnlwgt']\n",
    "X = prediction_df.drop([' fnlwgt'], axis=1)\n",
    "print('------FULL FRAME------')\n",
    "print(prediction_df.loc[0])\n",
    "print('-----JUST Y---------')\n",
    "print(Y.loc[0])\n",
    "print('-----JUST X--------')\n",
    "print(X.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112,)\n",
      "0\n",
      "(112,)\n",
      "1\n",
      "(32561, 7)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now we convert our X to a numerical matrix\n",
    "#\n",
    "\n",
    "def Row_To_Array(row):\n",
    "    '''Helper function to convert a row to a single array'''\n",
    "    row_arr = np.empty(shape=0)\n",
    "    for i in row.iteritems():\n",
    "        row_arr = np.append(row_arr, i[1])\n",
    "    return row_arr\n",
    "\n",
    "#Lets try it out and see our shapes...\n",
    "for idx, row in X[0:2].iterrows():\n",
    "    print(Row_To_Array(row).shape)\n",
    "    print(idx)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we have 112 values in 32,561 rows.\n",
    "\n",
    "Our old data frame had 32561 rows and 7 columns.\n",
    "We need to build a new matrix with 32561 rows, but 112 values, where the last value is our prediction value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Actually convert X to a matrix\n",
    "#\n",
    "matrix = np.empty(shape=(32561,112))\n",
    "\n",
    "for idx, row in X.iterrows():\n",
    "    matrix[idx] = Row_To_Array(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Convert Y to a matrix\n",
    "#\n",
    "\n",
    "Y = Y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 112)\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   1.   0.   0.   0.  40.]\n",
      "77516\n"
     ]
    }
   ],
   "source": [
    "#Quick Spot check.\n",
    "print(matrix.shape)\n",
    "print(matrix[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(matrix, Y, train_size = 0.8, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561\n",
      "26048\n",
      "6513\n",
      "32561\n"
     ]
    }
   ],
   "source": [
    "#Show that it splits effectively.\n",
    "print(len(X))\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(x_train) + len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LinReg = LinearRegression(n_jobs = -1)\n",
    "LinReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 103580.22470316596\n",
      "MEAN AE: 76043.2007294718\n",
      "MEDIAN AE: 60349.10135689686\n",
      "R2: 0.02761449543342631\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "\n",
    "# Get some predictions\n",
    "predictions = LinReg.predict(x_test)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "med_ae = median_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "\n",
    "print('RMSE: {}'.format(rmse))\n",
    "print('MEAN AE: {}'.format(mae))\n",
    "print('MEDIAN AE: {}'.format(med_ae))\n",
    "print('R2: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6795.36801413  18973.86010804  30280.91119152  23987.94684451\n",
      "  23930.08100851  26572.69142684  27572.30270944  26212.95828645\n",
      "  20477.10053692  11965.5412312   16848.59768887  10472.60043789\n",
      "  12396.71710406  12604.79017975  17893.10396096  14756.36915534\n",
      "  17725.3213672   16165.88181015  14973.83741569  11625.28806353\n",
      "  10014.38324268   2880.54990453   9879.09877979   9221.31357131\n",
      "   1994.59866922   7913.36131535   8614.92954199  10713.31485042\n",
      "   3888.67643494  11363.57888695   7643.32832974  -1802.67161353\n",
      "  -4963.68937659 -10391.54852831  -9675.47336693  -3476.00947351\n",
      "  -3918.67862604  -2461.93352148    524.59854369   4487.26616046\n",
      "    779.77869626   5191.23950182    656.09761008 -14661.29655202\n",
      " -11648.11908304 -17537.19244989 -11453.73049932  -3256.29133197\n",
      "  -5625.1806502   -5682.98695022 -11640.59080707  -2324.15217311\n",
      "  -5389.68623753  11713.60962725 -10831.15221882   5006.14651155\n",
      " -17096.32343713 -20360.61018504 -28847.17532987 -11982.87941703\n",
      " -19461.57030717  -1410.46177291 -34121.2742246  -12514.20809724\n",
      " -34931.60921733 -38248.77268187  46315.2571978   14818.94032567\n",
      " -52210.74209132 -21113.83260377 -99178.67950495  10527.02734685\n",
      " -18159.84125953   6984.0343582   -6984.0343582  -57395.56302481\n",
      " -15445.6720768   53565.08587421   6329.39700885  12946.75221855\n",
      " -10417.0008212  -10847.04072035  37946.47171984 -11865.21005101\n",
      "  31722.70187506  -7497.78385734 -17618.06056368  40171.5772913\n",
      "  -8306.948112    -5096.92582728 -13301.26256613    311.77212222\n",
      "  -9113.21627622   -766.83369163 -12933.23948172  -2389.00103985\n",
      "  -9635.33108635  -6213.13185294  -4986.44310444   2945.69629059\n",
      "  -2668.67547697  -4272.2689071   -1613.38460099 -10565.54828528\n",
      "  37009.08702348   1623.01641159   2578.26995417   1939.75328251\n",
      "  -9013.07241195   6207.52317271  -3335.49040903   -151.20026252]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# You can get your weights; which can be very interesting for understanding\n",
    "# most positively or negatively impactful features\n",
    "#\n",
    "print(LinReg.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
